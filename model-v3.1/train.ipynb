{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydot) (3.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.18.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install pydot\n",
    "%pip install tensorflow\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from constants import (\n",
    "    DATA_INPUT_PATH,\n",
    "    MODEL_PATH,\n",
    "    METADATA_PATH,\n",
    ")\n",
    "\n",
    "CLASSES = {\n",
    "    0: \"resting\",\n",
    "    1: \"palm up\",\n",
    "    2: \"closed fist\",\n",
    "    3: \"ok\",\n",
    "    4: \"pointer finger\",\n",
    "    5: \"peace\",\n",
    "    6: \"shaa\",\n",
    "    7: \"peace among worlds\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the files in the data dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('data/emg_gestures_data_20250219_122322.csv')]\n"
     ]
    }
   ],
   "source": [
    "# Read all of the files in the data folder\n",
    "files_in_folder = Path(DATA_INPUT_PATH).glob(\"*.csv\")\n",
    "\n",
    "files = [x for x in files_in_folder]\n",
    "print([file for file in files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .csv(s) to dataframes and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gesture_id   s1   s2   s3  s4   s5   s6   s7   s8\n",
      "0           0  366  558  412  97  131  379  114  257\n",
      "1           0  191  419  374  73   85  200   65  122\n",
      "2           0  127  334  372  71   66  110   47   82\n",
      "3           0  109  320  355  70   78   92   45   76\n",
      "4           0   91  263  357  67   78   83   41   67\n",
      "Shape of dataframe before removing duplicates (9830, 9)\n",
      "Shape of dataframe after removing duplicates (9830, 9)\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the files\n",
    "dfs = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(str(file))\n",
    "    dfs.append(df)\n",
    "        \n",
    "# Convert the data to a DataFrame\n",
    "df = pd.concat([x for x in dfs], axis=0)\n",
    "\n",
    "columns = [\"gesture_id\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\"]\n",
    "df = df[columns]\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Before removing duplicates\n",
    "print(f\"Shape of dataframe before removing duplicates {df.shape}\")\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Shape of dataframe after removing duplicates {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9830, 9)\n",
      "   gesture_id          s1          s2          s3         s4         s5  \\\n",
      "0         0.0  115.739362  176.455093  130.285840  30.674093  41.425837   \n",
      "1         0.0  130.551522  220.663771  175.960223  38.390103  49.382183   \n",
      "2         0.0  136.589165  244.638713  211.661050  44.473588  53.611566   \n",
      "3         0.0  140.871218  264.741572  239.589023  49.677963  59.013558   \n",
      "4         0.0  143.780388  277.497748  264.854300  54.007407  63.960926   \n",
      "\n",
      "           s6         s7         s8  \n",
      "0  119.850323  36.049965  81.270536  \n",
      "1  135.514206  41.498193  89.962770  \n",
      "2  139.907469  44.079474  93.625317  \n",
      "3  142.900315  46.319542  96.660747  \n",
      "4  145.290743  48.099896  98.955546  \n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "window_size = 10  # Number of past samples to include\n",
    "\n",
    "# Extract feature columns (excluding label, if it exists)\n",
    "feature_columns = [col for col in df.columns if col != 'Label']\n",
    "features = df[feature_columns].to_numpy()\n",
    "\n",
    "# Convert features into a 3D array: [samples, features, time]\n",
    "n_samples = len(features)\n",
    "n_features = len(feature_columns)\n",
    "reshaped_data = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Get the last `window_size` rows or fewer for each sample\n",
    "    window = features[max(i - window_size + 1, 0):i + 1]\n",
    "    \n",
    "    # Pad the window if it has fewer than `window_size` rows\n",
    "    if len(window) < window_size:\n",
    "        padding = np.zeros((window_size - len(window), n_features))\n",
    "        window = np.vstack((padding, window))\n",
    "    \n",
    "    reshaped_data.append(window)\n",
    "\n",
    "# Convert list to 3D numpy array\n",
    "reshaped_data = np.stack(reshaped_data, axis=0)\n",
    "reshaped_data = reshaped_data.transpose(0, 2, 1)\n",
    "df[feature_columns] = np.sqrt(np.mean(np.square(reshaped_data), axis=2))\n",
    "    \n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and clean the data, then train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simpl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5885 - loss: 1.3329 - val_accuracy: 0.9650 - val_loss: 0.7917\n",
      "Epoch 2/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9720 - loss: 0.1486 - val_accuracy: 0.9841 - val_loss: 0.2439\n",
      "Epoch 3/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0867 - val_accuracy: 0.9886 - val_loss: 0.0714\n",
      "Epoch 4/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0720 - val_accuracy: 0.9911 - val_loss: 0.0320\n",
      "Epoch 5/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0554 - val_accuracy: 0.9949 - val_loss: 0.0194\n",
      "Epoch 6/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.0542 - val_accuracy: 0.9962 - val_loss: 0.0153\n",
      "Epoch 7/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0381 - val_accuracy: 0.9955 - val_loss: 0.0135\n",
      "Epoch 8/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0431 - val_accuracy: 0.9981 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0404 - val_accuracy: 0.9968 - val_loss: 0.0094\n",
      "Epoch 10/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0379 - val_accuracy: 0.9981 - val_loss: 0.0082\n",
      "Epoch 11/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0324 - val_accuracy: 0.9981 - val_loss: 0.0097\n",
      "Epoch 12/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0323 - val_accuracy: 0.9968 - val_loss: 0.0130\n",
      "Epoch 13/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0303 - val_accuracy: 0.9955 - val_loss: 0.0134\n",
      "Epoch 14/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0315 - val_accuracy: 0.9968 - val_loss: 0.0111\n",
      "Epoch 15/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0262 - val_accuracy: 0.9981 - val_loss: 0.0070\n",
      "Epoch 16/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0275 - val_accuracy: 0.9987 - val_loss: 0.0064\n",
      "Epoch 17/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0221 - val_accuracy: 0.9987 - val_loss: 0.0058\n",
      "Epoch 18/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0256 - val_accuracy: 0.9987 - val_loss: 0.0060\n",
      "Epoch 19/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0270 - val_accuracy: 0.9987 - val_loss: 0.0069\n",
      "Epoch 20/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0180 - val_accuracy: 0.9981 - val_loss: 0.0080\n",
      "Epoch 21/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0176 - val_accuracy: 0.9975 - val_loss: 0.0073\n",
      "Epoch 22/100\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0179 - val_accuracy: 0.9987 - val_loss: 0.0066\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0077\n",
      "Test accuracy: 0.9964394569396973\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['gesture_id'])\n",
    "y = df['gesture_id']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for Conv1D\n",
    "X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# # filter for valid classes because the data is not clean\n",
    "# valid_classes = [0, 2, 3]\n",
    "# mask_train = y_train.isin(valid_classes)\n",
    "# mask_test = y_test.isin(valid_classes)\n",
    "\n",
    "# # apply the mask to the training and testing data\n",
    "# X_train_filtered = X_train_scaled[mask_train]\n",
    "# y_train_filtered = y_train[mask_train]\n",
    "\n",
    "# X_test_filtered = X_test_scaled[mask_test]\n",
    "# y_test_filtered = y_test[mask_test]\n",
    "\n",
    "# one hot encode the target data\n",
    "y_train_categorical = to_categorical(y_train, num_classes=8)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=8)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Compile the model with categorical crossentropy for multi-class classification\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model using the filtered training data\n",
    "model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train_categorical, \n",
    "    epochs=100, \n",
    "    batch_size=64, \n",
    "    validation_split=0.2, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the filtered test set\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test_categorical)\n",
    "\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(f\"model/{MODEL_PATH}\")\n",
    "\n",
    "# Save the scaler and the column names to a pickle file\n",
    "with open(f\"model/{METADATA_PATH}\", 'wb') as f:\n",
    "    pickle.dump((scaler, X_train.columns), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "Predicted class: 2 - closed fist\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Predicted class: 5 - peace\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Predicted class: 2 - closed fist\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted class: 2 - closed fist\n"
     ]
    }
   ],
   "source": [
    "# thumbs-up then peace-sign\n",
    "emg_data = [\n",
    "    [160,245,126,32,28,25,26,99], # thumbs-up\n",
    "    [67,197,559,104,41,82,257,169], # peace-sign\n",
    "    [205,440,165,40,27,83,229,226], # gun-fingers\n",
    "    [416,434,134,71,36,48,102,103] # fist\n",
    "]\n",
    "\n",
    "for data in emg_data:\n",
    "    emg_features_df = pd.DataFrame([data], columns=X_train.columns)\n",
    "\n",
    "    emg_features_scaled = scaler.transform(emg_features_df)\n",
    "    emg_features_reshaped = emg_features_scaled.reshape(1, -1)\n",
    "\n",
    "    prediction = model.predict(emg_features_reshaped)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    print(f\"Predicted class: {predicted_class} - {CLASSES[predicted_class]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
